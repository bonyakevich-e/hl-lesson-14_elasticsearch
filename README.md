### OTUS High Load Lesson #14 | Subject: Настройка централизованного сбора логов в кластер Elasticsearch
-----------------
### ЦЕЛЬ: Настроить централизованный сбор логов с различных серверов проекта и их хранение в кластер Elasticsearch для удобного поиска и анализа
-----------------
### ТРЕБОВАНИЯ: 
#### 1. Развертывание кластера Elasticsearch
- Создать и настроить кластер Elasticsearch. Развернуть кластер Elasticsearch, состоящий из как минимум трех виртуальных машин (ВМ), которые будут выполнять функции узлов кластера.
- Настроить узлы кластера. Обеспечить правильную конфигурацию узлов для работы в кластере, включая настройку сетевого взаимодействия и параметров кластера (например, discovery.seed_hosts, cluster.initial_master_nodes).
#### 2.  Настройка сбора логов
- Выбрать инструмент для сбора логов. Решить какой инструмент будет использоваться для сбора логов с серверов. Возможные варианты включают Filebeat, Logstash или другие подходящие агрегаторы логов.
- Установить и настроить инструмент для сбора логов. Установить выбранный инструмент на все серверы проекта, включая веб-серверы, балансеры и базы данных. Настроить его для отправки логов в кластер Elasticsearch.
- Конфигурировать шаблоны и индексы. Создать и настроить шаблоны индексов и правила для обработки логов в Elasticsearch, чтобы обеспечить правильное хранение и структурирование данных.
#### 3. Проверка и тестирование
- Проверить сбор логов. Убедиться, что логи корректно собираются и отправляются в Elasticsearch. Проверить, что данные появляются в Elasticsearch и могут быть проанализированы.
- Настроить визуализацию. Опционально, для удобства анализа, настроить инструменты визуализации, такие как Kibana, для просмотра и анализа собранных логов.
----------------
### ОЖИДАЕМЫЕ РЕЗУЛЬТАТЫ:
- Работает кластер Elasticsearch из минимум трех узлов.
- Логи со всех указанных серверов (веб-серверы, балансеры, базы данных) успешно собираются и хранятся в Elasticsearch.
- Настроена возможность просмотра и анализа логов в Elasticsearch.
